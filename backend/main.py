"""
Mriia AI Tutor - FastAPI Backend
–ò—Å–ø–æ–ª—å–∑—É–µ—Ç –ö–û–î –ò–ó agent.py –∏ hybrid_retriever.py
"""

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel, Field
from typing import List, Dict, Any, Optional
import uvicorn
import os
from pathlib import Path
from datetime import datetime
import logging

# –ò–ú–ü–û–†–¢–ò–†–£–ï–ú –í–ê–® –ö–û–î
from agent import (
    _get_llm_reasoning,
    _get_llm_classification, 
    _load_rag_data,
    _retrieve_context,
    SUBJECT_MAP
)
from hybrid_retriever import HybridRetriever, HybridConfig

# –ù–∞—Å—Ç—Ä–æ–π–∫–∞ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏—è
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# FastAPI app
app = FastAPI(
    title="Mriia AI Tutor API",
    description="AI Tutor using agent.py and hybrid_retriever.py",
    version="3.0.0"
)

# CORS
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# –ì–ª–æ–±–∞–ª—å–Ω—ã–µ –æ–±—ä–µ–∫—Ç—ã
retriever: Optional[HybridRetriever] = None
llm_reasoning = None
rag_data = None

# ============================================================================
# Pydantic Models
# ============================================================================

class TeacherRequest(BaseModel):
    topic: str
    grade: int = Field(..., ge=8, le=9)
    subject: str
    use_rag: bool = True

class Exercise(BaseModel):
    question_id: str
    question_text: str
    test_type: str = "single_choice"
    answers: List[str]
    correct_answer_indices: List[int]
    difficulty: str = "medium"
    metadata: Dict[str, Any] = {}

class LearningMaterial(BaseModel):
    topic: str
    grade: int
    subject: str
    summary: str
    explanation: str
    key_concepts: List[str]
    source_references: List[Dict[str, Any]]
    exercises: List[Exercise]
    rag_used: bool = False
    generated_at: str = Field(default_factory=lambda: datetime.now().isoformat())

class StudentAnswer(BaseModel):
    question_id: str
    selected_answer_index: int

class StudentProfile(BaseModel):
    student_id: int
    grade: int
    recent_scores: List[Dict[str, Any]] = []

class Correction(BaseModel):
    question_id: str
    is_correct: bool
    student_answer: str
    correct_answer: str
    explanation: str

class Recommendation(BaseModel):
    topic: str
    reason: str
    priority: str = "medium"

class AssessmentRequest(BaseModel):
    student_answers: List[StudentAnswer]
    exercises: List[Exercise]
    student_profile: Optional[StudentProfile] = None

class AssessmentResponse(BaseModel):
    score: float
    total_questions: int
    correct_answers: int
    corrections: List[Correction]
    performance_analysis: str
    recommendations: List[Recommendation]
    next_steps: List[str]

# ============================================================================
# Startup
# ============================================================================

@app.on_event("startup")
async def startup_event():
    """–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏—Å–ø–æ–ª—å–∑—É—è –í–ê–® –ö–û–î"""
    global retriever, llm_reasoning, rag_data
    
    logger.info("="*80)
    logger.info("üöÄ Starting Mriia AI Tutor - Based on YOUR code")
    logger.info("="*80)
    
    # 1. –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –í–ê–®–ò–ú —Å–ø–æ—Å–æ–±–æ–º –∏–∑ agent.py
    logger.info("üìö Loading RAG data using agent.py...")
    try:
        rag_data = _load_rag_data()
        logger.info(f"‚úÖ Loaded {len(rag_data)} RAG datasets")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not load RAG data: {e}")
        rag_data = {}
    
    # 2. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º Hybrid Retriever –∏–∑ –í–ê–®–ï–ì–û –∫–æ–¥–∞
    logger.info("üîç Initializing HybridRetriever...")
    try:
        retriever = HybridRetriever(config=HybridConfig(
            final_top_k=5,
            use_reranking=True,
            use_query_expansion=True
        ))
        
        # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –≤ retriever –µ—Å–ª–∏ –µ—Å—Ç—å
        if "toc_gemini" in rag_data:
            logger.info("Loading TOC data into retriever...")
            # retriever.load_toc_data(rag_data["toc_gemini"])
        
        logger.info("‚úÖ HybridRetriever initialized")
    except Exception as e:
        logger.warning(f"‚ö†Ô∏è Could not initialize retriever: {e}")
        retriever = None
    
    # 3. –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ–º LLM –í–ê–®–ò–ú —Å–ø–æ—Å–æ–±–æ–º –∏–∑ agent.py  
    logger.info("ü§ñ Initializing LLM client...")
    try:
        llm_reasoning = _get_llm_reasoning()
        logger.info("‚úÖ LLM client initialized")
    except Exception as e:
        logger.error(f"‚ùå Could not initialize LLM: {e}")
        llm_reasoning = None
    
    logger.info("="*80)
    logger.info("‚úÖ Backend ready!")
    logger.info("="*80)

# ============================================================================
# Helper Functions
# ============================================================================

def parse_llm_response(response_text: str) -> Dict[str, str]:
    """–ü–∞—Ä—Å–∏—Ç –æ—Ç–≤–µ—Ç LLM –Ω–∞ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç—ã"""
    parts = {}
    
    if "–ö–û–ù–°–ü–ï–ö–¢:" in response_text:
        parts_split = response_text.split("–ö–û–ù–°–ü–ï–ö–¢:")
        if len(parts_split) > 1:
            content = parts_split[1]
            if "–ü–û–Ø–°–ù–ï–ù–ù–Ø:" in content:
                summary, rest = content.split("–ü–û–Ø–°–ù–ï–ù–ù–Ø:", 1)
                parts["summary"] = summary.strip()
                if "–¢–ï–°–¢–ò:" in rest:
                    explanation, tests = rest.split("–¢–ï–°–¢–ò:", 1)
                    parts["explanation"] = explanation.strip()
                    parts["tests"] = tests.strip()
                else:
                    parts["explanation"] = rest.strip()
            else:
                parts["summary"] = content.strip()
    
    return parts

def parse_exercises_from_text(text: str) -> List[Dict]:
    """–ü–∞—Ä—Å–∏—Ç —Ç–µ—Å—Ç–æ–≤—ã–µ –∑–∞–¥–∞–Ω–∏—è –∏–∑ —Ç–µ–∫—Å—Ç–∞ LLM"""
    exercises = []
    
    # –ü—Ä–æ—Å—Ç–æ–π –ø–∞—Ä—Å–∏–Ω–≥ - –∏—â–µ–º –±–ª–æ–∫–∏ —Å –ü–ò–¢–ê–ù–ù–Ø
    blocks = text.split("–ü–ò–¢–ê–ù–ù–Ø:")
    
    for i, block in enumerate(blocks[1:], 1):  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –ø–µ—Ä–≤—ã–π –ø—É—Å—Ç–æ–π
        try:
            lines = [l.strip() for l in block.split("\n") if l.strip()]
            
            question = lines[0] if lines else ""
            answers = []
            correct = 0
            
            for line in lines[1:]:
                if line.startswith("–ê)") or line.startswith("A)"):
                    answers.append(line[2:].strip())
                elif line.startswith("–ë)") or line.startswith("B)"):
                    answers.append(line[2:].strip())
                elif line.startswith("–í)") or line.startswith("C)"):
                    answers.append(line[2:].strip())
                elif line.startswith("–ì)") or line.startswith("D)"):
                    answers.append(line[2:].strip())
                elif "–ü–†–ê–í–ò–õ–¨–ù–ê" in line.upper():
                    ans_letter = line.split(":")[-1].strip().upper()
                    correct = {"–ê": 0, "–ë": 1, "–í": 2, "–ì": 3, 
                             "A": 0, "B": 1, "C": 2, "D": 3}.get(ans_letter, 0)
            
            if question and len(answers) == 4:
                exercises.append({
                    "question_id": f"gen_{i}",
                    "question_text": question,
                    "test_type": "single_choice",
                    "answers": answers,
                    "correct_answer_indices": [correct],
                    "difficulty": "medium",
                    "metadata": {"generated": True}
                })
        except:
            continue
    
    return exercises

# ============================================================================
# API Endpoints
# ============================================================================

@app.get("/")
async def root():
    return {
        "message": "Mriia AI Tutor v3.0",
        "description": "Based on YOUR agent.py and hybrid_retriever.py",
        "llm_ready": llm_reasoning is not None,
        "rag_ready": rag_data is not None and len(rag_data) > 0
    }

@app.get("/health")
async def health():
    return {
        "status": "healthy",
        "llm_initialized": llm_reasoning is not None,
        "rag_loaded": rag_data is not None,
        "retriever_ready": retriever is not None
    }

@app.post("/api/generate-material", response_model=LearningMaterial)
async def generate_material(request: TeacherRequest):
    """
    –ì–µ–Ω–µ—Ä–∞—Ü–∏—è –º–∞—Ç–µ—Ä–∏–∞–ª–∞ –∏—Å–ø–æ–ª—å–∑—É—è –í–ê–® –ö–û–î:
    1. agent._retrieve_context() –¥–ª—è RAG
    2. agent._get_llm_reasoning() –¥–ª—è LLM
    """
    
    logger.info(f"üìö Generate request: {request.topic}, {request.subject}, grade {request.grade}")
    
    if llm_reasoning is None:
        raise HTTPException(500, "LLM not initialized")
    
    try:
        # –®–ê–ì 1: RAG - –∏—Å–ø–æ–ª—å–∑—É–µ–º –í–ê–®–£ —Ñ—É–Ω–∫—Ü–∏—é –∏–∑ agent.py
        context = ""
        if request.use_rag:
            logger.info("üîç Using _retrieve_context from agent.py...")
            context = _retrieve_context(
                question_text=request.topic,
                subject=request.subject,
                top_k=3
            )
            logger.info(f"‚úÖ Retrieved {len(context)} chars of context")
        
        # –®–ê–ì 2: LLM –≥–µ–Ω–µ—Ä–∞—Ü–∏—è - –∏—Å–ø–æ–ª—å–∑—É–µ–º –í–ê–®–ï–ì–û –∫–ª–∏–µ–Ω—Ç–∞
        from langchain_core.messages import SystemMessage, HumanMessage
        
        subject_name = SUBJECT_MAP.get(request.subject, request.subject)
        
        system_prompt = f"""–¢–∏ - –¥–æ—Å–≤—ñ–¥—á–µ–Ω–∏–π –≤—á–∏—Ç–µ–ª—å –¥–ª—è {request.grade} –∫–ª–∞—Å—É.
–ü—Ä–µ–¥–º–µ—Ç: {subject_name}
–°—Ç–≤–æ—Ä—é–π –Ω–∞–≤—á–∞–ª—å–Ω—ñ –º–∞—Ç–µ—Ä—ñ–∞–ª–∏ —É–∫—Ä–∞—ó–Ω—Å—å–∫–æ—é –º–æ–≤–æ—é."""

        user_prompt = f"""–°—Ç–≤–æ—Ä–∏ –Ω–∞–≤—á–∞–ª—å–Ω–∏–π –º–∞—Ç–µ—Ä—ñ–∞–ª –Ω–∞ —Ç–µ–º—É: "{request.topic}"

{f"–ö–æ–Ω—Ç–µ–∫—Å—Ç –∑ –ø—ñ–¥—Ä—É—á–Ω–∏–∫–∞:\n{context[:1500]}\n" if context else ""}

–°—Ç–≤–æ—Ä–∏ —É —Ñ–æ—Ä–º–∞—Ç—ñ:

–ö–û–ù–°–ü–ï–ö–¢:
[200-300 —Å–ª—ñ–≤ –∫–æ—Ä–æ—Ç–∫–æ–≥–æ –∫–æ–Ω—Å–ø–µ–∫—Ç—É]

–ü–û–Ø–°–ù–ï–ù–ù–Ø:
[400-600 —Å–ª—ñ–≤ –¥–µ—Ç–∞–ª—å–Ω–æ–≥–æ –ø–æ—è—Å–Ω–µ–Ω–Ω—è –∑ –ø—Ä–∏–∫–ª–∞–¥–∞–º–∏]

–¢–ï–°–¢–ò:
–ü–ò–¢–ê–ù–ù–Ø: [—Ç–µ–∫—Å—Ç –ø–∏—Ç–∞–Ω–Ω—è 1]
–ê) [–≤–∞—Ä—ñ–∞–Ω—Ç –ê]
–ë) [–≤–∞—Ä—ñ–∞–Ω—Ç –ë]
–í) [–≤–∞—Ä—ñ–∞–Ω—Ç –í]
–ì) [–≤–∞—Ä—ñ–∞–Ω—Ç –ì]
–ü–†–ê–í–ò–õ–¨–ù–ê_–í–Ü–î–ü–û–í–Ü–î–¨: [–ê/–ë/–í/–ì]

[... —â–µ 9 –ø–∏—Ç–∞–Ω—å ...]
"""
        
        messages = [
            SystemMessage(content=system_prompt),
            HumanMessage(content=user_prompt)
        ]
        
        logger.info("ü§ñ Calling LLM...")
        response = llm_reasoning.invoke(messages)
        content_text = response.content
        
        logger.info(f"‚úÖ LLM returned {len(content_text)} chars")
        
        # –®–ê–ì 3: –ü–∞—Ä—Å–∏–Ω–≥ –æ—Ç–≤–µ—Ç–∞
        parsed = parse_llm_response(content_text)
        
        summary = parsed.get("summary", content_text[:500])
        explanation = parsed.get("explanation", content_text[500:1500] if len(content_text) > 500 else "")
        
        # –ü–∞—Ä—Å–∏–º —É–ø—Ä–∞–∂–Ω–µ–Ω–∏—è
        exercises = []
        if "tests" in parsed:
            exercises = parse_exercises_from_text(parsed["tests"])
        
        # –ï—Å–ª–∏ –Ω–µ —Ä–∞—Å–ø–∞—Ä—Å–∏–ª–∏—Å—å, —Å–æ–∑–¥–∞–µ–º –º–∏–Ω–∏–º—É–º
        if len(exercises) < 3:
            exercises = parse_exercises_from_text(content_text)
        
        # –ö–ª—é—á–µ–≤—ã–µ –∫–æ–Ω—Ü–µ–ø—Ü–∏–∏
        key_concepts = [
            line.strip("- ‚Ä¢").strip()
            for line in summary.split("\n")
            if line.strip().startswith(("-", "‚Ä¢"))
        ][:5]
        
        # –ò—Å—Ç–æ—á–Ω–∏–∫–∏
        source_refs = []
        if context:
            source_refs.append({
                "type": "rag",
                "preview": context[:200],
                "length": len(context)
            })
        
        return LearningMaterial(
            topic=request.topic,
            grade=request.grade,
            subject=request.subject,
            summary=summary,
            explanation=explanation,
            key_concepts=key_concepts,
            source_references=source_refs,
            exercises=[Exercise(**ex) for ex in exercises[:10]],
            rag_used=len(context) > 0
        )
        
    except Exception as e:
        logger.error(f"‚ùå Error: {e}", exc_info=True)
        raise HTTPException(500, f"Generation error: {str(e)}")

@app.post("/api/assess-student", response_model=AssessmentResponse)
async def assess_student(request: AssessmentRequest):
    """–û—Ü–µ–Ω–∏–≤–∞–Ω–∏–µ —É—á–µ–Ω–∏–∫–∞ –∏—Å–ø–æ–ª—å–∑—É—è –í–ê–® LLM"""
    
    logger.info(f"üìä Assessment: {len(request.student_answers)} answers")
    
    if llm_reasoning is None:
        raise HTTPException(500, "LLM not initialized")
    
    try:
        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –æ—Ç–≤–µ—Ç–æ–≤
        corrections = []
        correct_count = 0
        
        ex_map = {ex.question_id: ex for ex in request.exercises}
        
        for ans in request.student_answers:
            ex = ex_map.get(ans.question_id)
            if not ex:
                continue
            
            is_correct = ans.selected_answer_index in ex.correct_answer_indices
            if is_correct:
                correct_count += 1
            
            student_ans = ex.answers[ans.selected_answer_index] if ans.selected_answer_index < len(ex.answers) else "?"
            correct_ans = ex.answers[ex.correct_answer_indices[0]] if ex.correct_answer_indices else "?"
            
            corrections.append(Correction(
                question_id=ans.question_id,
                is_correct=is_correct,
                student_answer=student_ans,
                correct_answer=correct_ans,
                explanation="‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ!" if is_correct else f"‚ùå –ü—Ä–∞–≤–∏–ª—å–Ω–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥—å: {correct_ans}"
            ))
        
        score = (correct_count / len(request.student_answers) * 100) if request.student_answers else 0
        
        # LLM —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–∏
        from langchain_core.messages import SystemMessage, HumanMessage
        
        rec_prompt = f"""–ü—Ä–æ–∞–Ω–∞–ª—ñ–∑—É–π —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ —É—á–Ω—è:
- –í—Å—å–æ–≥–æ –ø–∏—Ç–∞–Ω—å: {len(request.student_answers)}
- –ü—Ä–∞–≤–∏–ª—å–Ω–∏—Ö: {correct_count}
- –í—ñ–¥—Å–æ—Ç–æ–∫: {score:.1f}%

–°—Ç–≤–æ—Ä–∏:
1. –ê–ù–ê–õ–Ü–ó (2-3 —Ä–µ—á–µ–Ω–Ω—è)
2. –†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á (3-5 –ø—É–Ω–∫—Ç—ñ–≤ —â–æ –ø–æ–∫—Ä–∞—â–∏—Ç–∏)
3. –ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò (3 –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ñ –¥—ñ—ó)

–§–æ—Ä–º–∞—Ç:
–ê–ù–ê–õ–Ü–ó: ...
–†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:
- ...
–ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò:
- ...
"""
        
        messages = [
            SystemMessage(content="–¢–∏ - –ø–µ–¥–∞–≥–æ–≥ —è–∫–∏–π –¥–∞—î –∫–æ–Ω—Å—Ç—Ä—É–∫—Ç–∏–≤–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó"),
            HumanMessage(content=rec_prompt)
        ]
        
        response = llm_reasoning.invoke(messages)
        rec_text = response.content
        
        # –ü–∞—Ä—Å–∏–Ω–≥ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü–∏–π
        analysis = rec_text.split("–†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")[0].replace("–ê–ù–ê–õ–Ü–ó:", "").strip()
        
        recommendations = []
        if "–†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:" in rec_text:
            rec_part = rec_text.split("–†–ï–ö–û–ú–ï–ù–î–ê–¶–Ü–á:")[1]
            if "–ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò:" in rec_part:
                rec_part = rec_part.split("–ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò:")[0]
            
            for line in rec_part.split("\n"):
                if line.strip().startswith("-"):
                    recommendations.append(Recommendation(
                        topic="–ü–æ–∫—Ä–∞—â–µ–Ω–Ω—è",
                        reason=line.strip("- ").strip(),
                        priority="high" if score < 60 else "medium"
                    ))
        
        next_steps = []
        if "–ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò:" in rec_text:
            steps_part = rec_text.split("–ù–ê–°–¢–£–ü–ù–Ü_–ö–†–û–ö–ò:")[1]
            for line in steps_part.split("\n"):
                if line.strip().startswith("-"):
                    next_steps.append(line.strip("- ").strip())
        
        return AssessmentResponse(
            score=score,
            total_questions=len(request.student_answers),
            correct_answers=correct_count,
            corrections=corrections,
            performance_analysis=analysis,
            recommendations=recommendations[:5],
            next_steps=next_steps[:5]
        )
        
    except Exception as e:
        logger.error(f"‚ùå Assessment error: {e}", exc_info=True)
        raise HTTPException(500, f"Assessment error: {str(e)}")

@app.get("/api/subjects")
async def get_subjects():
    return {
        "subjects": [
            {"id": "algebra", "name": "–ê–ª–≥–µ–±—Ä–∞", "grades": [8, 9]},
            {"id": "ukrainian_language", "name": "–£–∫—Ä–∞—ó–Ω—Å—å–∫–∞ –º–æ–≤–∞", "grades": [8, 9]},
            {"id": "history_ukraine", "name": "–Ü—Å—Ç–æ—Ä—ñ—è –£–∫—Ä–∞—ó–Ω–∏", "grades": [8, 9]}
        ]
    }

# ============================================================================
# Run
# ============================================================================

if __name__ == "__main__":
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)
