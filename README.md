# üéì Mriia AI Tutor ‚Äî Lapathon 2026

**–ü–æ–≤–Ω–µ —Ä—ñ—à–µ–Ω–Ω—è –Ω–∞ –±–∞–∑—ñ –∫–æ–¥—É –∑ Lapathon3.zip**

## ‚úÖ –©–æ –≤–∫–ª—é—á–µ–Ω–æ

### Backend (FastAPI)

* ‚úÖ **agent.py** ‚Äî –∫–æ–¥ –∑ LLM —Ç–∞ RAG
* ‚úÖ **hybrid_retriever.py** ‚Äî –ø—Ä–æ—Å—É–Ω—É—Ç–∏–π retriever
* ‚úÖ **main.py** ‚Äî FastAPI-–æ–±–≥–æ—Ä—Ç–∫–∞ –Ω–∞–¥ –æ—Å–Ω–æ–≤–Ω–æ—é –ª–æ–≥—ñ–∫–æ—é

### Frontend (Streamlit)

* ‚úÖ UI –¥–ª—è –≤—á–∏—Ç–µ–ª—è —Ç–∞ —É—á–Ω—è
* ‚úÖ –î–≤–∞ —Ä–µ–∂–∏–º–∏ —Ä–æ–±–æ—Ç–∏

### –î–∞–Ω—ñ

* ‚úÖ –ü—ñ–¥—Ç—Ä–∏–º–∫–∞ Parquet-—Ñ–∞–π–ª—ñ–≤
* ‚úÖ –°—É–º—ñ—Å–Ω—ñ—Å—Ç—å –∑ –Ω–∞—è–≤–Ω–æ—é —Å—Ç—Ä—É–∫—Ç—É—Ä–æ—é –¥–∞–Ω–∏—Ö

## üöÄ –®–≤–∏–¥–∫–∏–π —Å—Ç–∞—Ä—Ç

### –í–∞—Ä—ñ–∞–Ω—Ç 1: Docker

```bash
# 1. –†–æ–∑–ø–∞–∫—É–≤–∞—Ç–∏
tar -xzf mriia_hackathon.tar.gz
cd mriia_hackathon

# 2. –ü–æ–º—ñ—Å—Ç–∏—Ç–∏ Parquet-—Ñ–∞–π–ª–∏ –≤ data/
cp /—à–ª—è—Ö/–¥–æ/*.parquet data/

# 3. –ó–∞–ø—É—Å—Ç–∏—Ç–∏
docker-compose up --build

# 4. –í—ñ–¥–∫—Ä–∏—Ç–∏
http://localhost:8501  # Frontend
http://localhost:8000  # Backend API
http://localhost:8000/docs  # Swagger
```

### –í–∞—Ä—ñ–∞–Ω—Ç 2: –õ–æ–∫–∞–ª—å–Ω–æ

```bash
# Backend
cd backend
pip install -r requirements.txt
python main.py

# Frontend (–≤ —ñ–Ω—à–æ–º—É —Ç–µ—Ä–º—ñ–Ω–∞–ª—ñ)
cd frontend  
pip install -r requirements.txt
streamlit run app.py
```

## üìÇ –°—Ç—Ä—É–∫—Ç—É—Ä–∞ –ø—Ä–æ—î–∫—Ç—É

```
mriia_hackathon/
‚îú‚îÄ‚îÄ backend/
‚îÇ   ‚îú‚îÄ‚îÄ agent.py              # –û—Å–Ω–æ–≤–Ω–∞ –ª–æ–≥—ñ–∫–∞ –∑ –∞—Ä—Ö—ñ–≤—É
‚îÇ   ‚îú‚îÄ‚îÄ hybrid_retriever.py   # Retriever –∑ –∞—Ä—Ö—ñ–≤—É
‚îÇ   ‚îú‚îÄ‚îÄ main.py               # FastAPI-–æ–±–≥–æ—Ä—Ç–∫–∞
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ frontend/
‚îÇ   ‚îú‚îÄ‚îÄ app.py
‚îÇ   ‚îú‚îÄ‚îÄ requirements.txt
‚îÇ   ‚îî‚îÄ‚îÄ Dockerfile
‚îú‚îÄ‚îÄ data/                     # Parquet-—Ñ–∞–π–ª–∏
‚îú‚îÄ‚îÄ .env                      # –ù–∞–ª–∞—à—Ç—É–≤–∞–Ω–Ω—è LLM
‚îú‚îÄ‚îÄ docker-compose.yml
‚îî‚îÄ‚îÄ README.md
```

## üîß –Ø–∫ —Ü–µ –ø—Ä–∞—Ü—é—î

### 1. RAG –Ω–∞ –æ—Å–Ω–æ–≤—ñ —ñ—Å–Ω—É—é—á–æ–≥–æ –∫–æ–¥—É

```python
from agent import _retrieve_context, _get_llm_reasoning

context = _retrieve_context(
    question_text=topic,
    subject=subject,
    top_k=3
)
```

### 2. –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è LLM-–∫–ª—ñ—î–Ω—Ç–∞

```python
llm = _get_llm_reasoning()

from langchain_core.messages import SystemMessage, HumanMessage

response = llm.invoke([
    SystemMessage(content="System prompt..."),
    HumanMessage(content="User query...")
])
```

### 3. HybridRetriever

```python
from hybrid_retriever import HybridRetriever, HybridConfig

retriever = HybridRetriever(config=HybridConfig())
# –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î—Ç—å—Å—è –≤ API endpoints
```

## üìä API Endpoints

### POST /api/generate-material

–ì–µ–Ω–µ—Ä—É—î –Ω–∞–≤—á–∞–ª—å–Ω–∏–π –º–∞—Ç–µ—Ä—ñ–∞–ª –∑ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è–º:

* RAG –¥–ª—è –ø–æ—à—É–∫—É –∫–æ–Ω—Ç–µ–∫—Å—Ç—É
* LLM –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü—ñ—ó –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ

–ó–∞–ø–∏—Ç:

```json
{
  "topic": "–ö–≤–∞–¥—Ä–∞—Ç–Ω—ñ —Ä—ñ–≤–Ω—è–Ω–Ω—è",
  "grade": 8,
  "subject": "algebra",
  "use_rag": true
}
```

–í—ñ–¥–ø–æ–≤—ñ–¥—å:

```json
{
  "summary": "...",
  "explanation": "...",
  "exercises": [...],
  "rag_used": true
}
```

### POST /api/assess-student

–û—Ü—ñ–Ω—é—î –≤—ñ–¥–ø–æ–≤—ñ–¥—ñ —É—á–Ω—è –∑–∞ –¥–æ–ø–æ–º–æ–≥–æ—é LLM.

## üîë –ö–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è

–£—Å—ñ –ø–∞—Ä–∞–º–µ—Ç—Ä–∏ –∑–±–µ—Ä—ñ–≥–∞—é—Ç—å—Å—è –≤ `.env`:

```bash
LLM_API_URL=https://api.lapathoniia.top/v1/chat/completions
LLM_API_KEY=sk-********************************
LLM_MODEL=lapa

RAG_TOP_K=3
USE_RAG=true
```

## üì¶ –†–æ–∑–º—ñ—â–µ–Ω–Ω—è –¥–∞–Ω–∏—Ö

Parquet-—Ñ–∞–π–ª–∏ –º–∞—é—Ç—å –±—É—Ç–∏ –≤ –∫–∞—Ç–∞–ª–æ–∑—ñ `data/`:

```
data/
‚îú‚îÄ‚îÄ toc_for_hackathon_with_subtopics.parquet
‚îú‚îÄ‚îÄ pages_for_hackathon.parquet
‚îî‚îÄ‚îÄ lms_questions_dev.parquet
```

Backend –∞–≤—Ç–æ–º–∞—Ç–∏—á–Ω–æ –∑–Ω–∞—Ö–æ–¥–∏—Ç—å —Ñ–∞–π–ª–∏ –ø—ñ–¥ —á–∞—Å –∑–∞–ø—É—Å–∫—É.

## üß™ –¢–µ—Å—Ç—É–≤–∞–Ω–Ω—è

```bash
# –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ —Å—Ç–∞–Ω—É —Å–µ—Ä–≤—ñ—Å—É
curl http://localhost:8000/health

# –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –º–∞—Ç–µ—Ä—ñ–∞–ª—É
curl -X POST http://localhost:8000/api/generate-material \
  -H "Content-Type: application/json" \
  -d '{
    "topic": "–ö–≤–∞–¥—Ä–∞—Ç–Ω—ñ —Ä—ñ–≤–Ω—è–Ω–Ω—è",
    "grade": 8,
    "subject": "algebra"
  }'
```

## üìù –õ–æ–≥–∏

–ü—Ä–∏–∫–ª–∞–¥ –ª–æ–≥—ñ–≤ –ø—ñ–¥ —á–∞—Å –∑–∞–ø—É—Å–∫—É:

```
üöÄ Starting Mriia AI Tutor
üìö Loading RAG data...
‚úÖ Loaded 4 RAG datasets
üîç Initializing HybridRetriever...
‚úÖ HybridRetriever initialized
ü§ñ Initializing LLM client...
‚úÖ LLM client initialized
‚úÖ Backend ready!
```

## üîç –û—Å–Ω–æ–≤–Ω—ñ –∫–æ–º–ø–æ–Ω–µ–Ω—Ç–∏

### agent.py

* `_load_rag_data()` ‚Äî –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è Parquet
* `_retrieve_context()` ‚Äî RAG-–ø–æ—à—É–∫
* `_get_llm_reasoning()` ‚Äî LLM-–∫–ª—ñ—î–Ω—Ç
* `_get_llm_classification()` ‚Äî –∫–ª–∞—Å–∏—Ñ—ñ–∫–∞—Ü—ñ—è
* `SUBJECT_MAP` ‚Äî –º–∞–ø—ñ–Ω–≥ –ø—Ä–µ–¥–º–µ—Ç—ñ–≤

### hybrid_retriever.py

* `HybridRetriever`
* `HybridConfig`
* FAISS-—ñ–Ω–¥–µ–∫—Å–∏
* BM25 sparse retrieval
* Reranking

## ‚ú® –ü–µ—Ä–µ–≤–∞–≥–∏ —Ä—ñ—à–µ–Ω–Ω—è

1. –ü–æ–≤—Ç–æ—Ä–Ω–µ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è –Ω–∞—è–≤–Ω–æ–≥–æ –∫–æ–¥—É
2. –ú—ñ–Ω—ñ–º–∞–ª—å–Ω—ñ –∑–º—ñ–Ω–∏ –≤ –ª–æ–≥—ñ—Ü—ñ
3. –ß—ñ—Ç–∫–∞ —Ç–∞ –∑—Ä–æ–∑—É–º—ñ–ª–∞ —Å—Ç—Ä—É–∫—Ç—É—Ä–∞
4. –ü—Ä–æ—Å—Ç–æ—Ç–∞ –ø—ñ–¥—Ç—Ä–∏–º–∫–∏ –π —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è
5. –Ñ–¥–∏–Ω–∞ –∫–æ–Ω—Ñ—ñ–≥—É—Ä–∞—Ü—ñ—è –¥–ª—è Backend —ñ Frontend

## üéØ –í—ñ–¥–ø–æ–≤—ñ–¥–Ω—ñ—Å—Ç—å –≤–∏–º–æ–≥–∞–º —Ö–∞–∫–∞—Ç–æ–Ω—É

‚úÖ –î–≤–∞ –æ—Å–Ω–æ–≤–Ω—ñ API endpoint‚Äô–∏
‚úÖ –†–æ–±–æ—Ç–∞ –∑ –ø—ñ–¥—Ä—É—á–Ω–∏–∫–∞–º–∏ —á–µ—Ä–µ–∑ RAG
‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è –Ω–∞–≤—á–∞–ª—å–Ω–æ–≥–æ –º–∞—Ç–µ—Ä—ñ–∞–ª—É
‚úÖ –ì–µ–Ω–µ—Ä–∞—Ü—ñ—è —Ç–µ—Å—Ç—ñ–≤
‚úÖ –ü–µ—Ä–µ–≤—ñ—Ä–∫–∞ –≤—ñ–¥–ø–æ–≤—ñ–¥–µ–π
‚úÖ –ü–µ—Ä—Å–æ–Ω–∞–ª—ñ–∑–æ–≤–∞–Ω—ñ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ü—ñ—ó
‚úÖ Frontend + Backend
‚úÖ Docker
‚úÖ –î–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

## üí° –î–æ–¥–∞—Ç–∫–æ–≤–æ

### Swagger-–¥–æ–∫—É–º–µ–Ω—Ç–∞—Ü—ñ—è

[http://localhost:8000/docs](http://localhost:8000/docs)

### Streamlit UI

[http://localhost:8501](http://localhost:8501)

---

**–†—ñ—à–µ–Ω–Ω—è –≥–æ—Ç–æ–≤–µ –¥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è —Ç–∞ —Ä–æ–∑—à–∏—Ä–µ–Ω–Ω—è üöÄ**
